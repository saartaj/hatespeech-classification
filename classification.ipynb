{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5ac9e6411db344fdc7aa564e07e86e4f3509fe4234c29ecf35c07eec4f9a18b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Hate Speech Classification Using ML-Algorithms & NLP "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile  \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting zipfile with python to read\n",
    "file = ZipFile('Basic_ML_Model_for_Text_Classification.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# using open function to open zipfile then reading csv using pandas\n",
    "df = pd.read_csv(file.open('final_dataset_basicmlmodel.csv'))\n",
    "\n",
    "# taking a glimpse of first 6 rows.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class balance check:\n0    3000\n1    2242\nName: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Label summary\n",
    "print('Class balance check:')\n",
    "print(df['label'].value_counts()) # counting labels\n",
    "df.drop('id', inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "125 .   @user ð d most impoant thing is to #enjoy your life - to be   - itâs all that matters. life is too sho. #pooh4u \n126 .  happy bihday chris evansððððððð a great actor and human ððð³ðð»ð¸ððð #chrisevans   #bihdayâ¦ \n127 .  our heas, thoughts, prayers go out to the more than 50 people who were murdered @ a gay nightclub in #florida   \n128 .   @user demoing guitars for new album #newalbum #indie #guitars   #echobelly \n129 .  retweeted lion pro (@user  #tgif #webmareting #seo #community #management   #weekend... \n130 .   â #nzd/usd: targets the 100 week sma at 0.7190   #blog #silver #gold #forex\n131 .   @user i've had pretty bad bihday weeks before, but so far this is the worst ever. ð #bihdayweeksucks #bithday27   #tâ¦\n132 .  so blessed to have worked with sa's best leading ladiesðð \n133 .  happiest place on eah ð« #disneysmagickingdom #disney #magickingdom #disneyland   #orlandoâ¦ \n134 .  is kinda   to be among humans again.\n"
     ]
    }
   ],
   "source": [
    "# choosen randomly few columns to get a fair ideal about comments made on the platform.\n",
    "\n",
    "for index, comment in enumerate(df['tweet'][125:135]):\n",
    "    print(index+125, '. ', comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_frame(text):\n",
    "    \"\"\"\n",
    "    This function will clean the data frame. It will let the go all the alphabates and filterout all other     characters.\n",
    "    \"\"\"\n",
    "    # Anything which will be other than a to z or A to Z and ' will be replaced by whitespace\n",
    "    text = re.sub(r'[^a-zA-Z\\']', ' ', text)  \n",
    "    # All the unicode characters will be removed\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    # all the letters will be lowered \n",
    "    text = text.lower()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        id  label                                              tweet  \\\n",
       "1125  1212      0   â #aud/usd: failures apparent at key resist...   \n",
       "1126  1213      0  because i am happy! ðð #happiness #minio...   \n",
       "1127  1214      0  when someone is doing the effo to make people ...   \n",
       "1128  1216      0  i'm super hungry but don't feel like cooking.....   \n",
       "1129  1217      0  new bikini from my amazon list âºï¸ big x to...   \n",
       "1130  1218      0         @user will definitely be reading these!  !   \n",
       "1131  1219      0  my new car should be ready middle of next week...   \n",
       "1132  1220      0  happy monday everyone! lets make it a good wee...   \n",
       "1133  1221      0                    after sex sex video free tube     \n",
       "1134  1222      0  looks like #knowledge is power - and #happines...   \n",
       "1135  1223      0  on our way to the #cmtredcarpet â¨   #tunein ...   \n",
       "\n",
       "                                             clean_text  \n",
       "1125        aud usd  failures apparent at key resist...  \n",
       "1126  because i am happy            happiness  minio...  \n",
       "1127  when someone is doing the effo to make people ...  \n",
       "1128  i'm super hungry but don't feel like cooking  ...  \n",
       "1129  new bikini from my amazon list        big x to...  \n",
       "1130          user will definitely be reading these      \n",
       "1131  my new car should be ready middle of next week...  \n",
       "1132  happy monday everyone  lets make it a good wee...  \n",
       "1133                    after sex sex video free tube    \n",
       "1134  looks like  knowledge is power   and  happines...  \n",
       "1135  on our way to the  cmtredcarpet        tunein ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1125</th>\n      <td>1212</td>\n      <td>0</td>\n      <td>â #aud/usd: failures apparent at key resist...</td>\n      <td>aud usd  failures apparent at key resist...</td>\n    </tr>\n    <tr>\n      <th>1126</th>\n      <td>1213</td>\n      <td>0</td>\n      <td>because i am happy! ðð #happiness #minio...</td>\n      <td>because i am happy            happiness  minio...</td>\n    </tr>\n    <tr>\n      <th>1127</th>\n      <td>1214</td>\n      <td>0</td>\n      <td>when someone is doing the effo to make people ...</td>\n      <td>when someone is doing the effo to make people ...</td>\n    </tr>\n    <tr>\n      <th>1128</th>\n      <td>1216</td>\n      <td>0</td>\n      <td>i'm super hungry but don't feel like cooking.....</td>\n      <td>i'm super hungry but don't feel like cooking  ...</td>\n    </tr>\n    <tr>\n      <th>1129</th>\n      <td>1217</td>\n      <td>0</td>\n      <td>new bikini from my amazon list âºï¸ big x to...</td>\n      <td>new bikini from my amazon list        big x to...</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>1218</td>\n      <td>0</td>\n      <td>@user will definitely be reading these!  !</td>\n      <td>user will definitely be reading these</td>\n    </tr>\n    <tr>\n      <th>1131</th>\n      <td>1219</td>\n      <td>0</td>\n      <td>my new car should be ready middle of next week...</td>\n      <td>my new car should be ready middle of next week...</td>\n    </tr>\n    <tr>\n      <th>1132</th>\n      <td>1220</td>\n      <td>0</td>\n      <td>happy monday everyone! lets make it a good wee...</td>\n      <td>happy monday everyone  lets make it a good wee...</td>\n    </tr>\n    <tr>\n      <th>1133</th>\n      <td>1221</td>\n      <td>0</td>\n      <td>after sex sex video free tube</td>\n      <td>after sex sex video free tube</td>\n    </tr>\n    <tr>\n      <th>1134</th>\n      <td>1222</td>\n      <td>0</td>\n      <td>looks like #knowledge is power - and #happines...</td>\n      <td>looks like  knowledge is power   and  happines...</td>\n    </tr>\n    <tr>\n      <th>1135</th>\n      <td>1223</td>\n      <td>0</td>\n      <td>on our way to the #cmtredcarpet â¨   #tunein ...</td>\n      <td>on our way to the  cmtredcarpet        tunein ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# adding new column called clean text in the data frame. Using lambda function to clean per tweet.S\n",
    "df['clean_text'] = df['tweet'].apply(lambda x: clean_frame(x))\n",
    "\n",
    "# taking glimpse to get confirmation of filter\n",
    "df.loc[1125:1135, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'also', 'am', 'an', 'and',\n",
    "              'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below',\n",
    "              'between', 'both', 'but', 'by', 'can', \"can't\", 'cannot', 'com', 'could', \"couldn't\", 'did',\n",
    "              \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'else', 'ever',\n",
    "              'few', 'for', 'from', 'further', 'get', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having',\n",
    "              'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how',\n",
    "              \"how's\", 'however', 'http', 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it',\n",
    "              \"it's\", 'its', 'itself', 'just', 'k', \"let's\", 'like', 'me', 'more', 'most', \"mustn't\", 'my', 'myself',\n",
    "              'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'otherwise', 'ought', 'our', 'ours',\n",
    "              'ourselves', 'out', 'over', 'own', 'r', 'same', 'shall', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\",\n",
    "              'should', \"shouldn't\", 'since', 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs',\n",
    "              'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\",\n",
    "              \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\",\n",
    "              'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where',\n",
    "              \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\",\n",
    "              'www', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_creation(text):\n",
    "    \"\"\"\n",
    "    Function will create frequency for the given corpses. \n",
    "    \"\"\"\n",
    "    word_list = []\n",
    "\n",
    "    for tweets in text.split():\n",
    "        # extending tweets\n",
    "        word_list.extend(tweets)\n",
    "        # creating series of words and counting their frequency.\n",
    "    word_freq = pd.Series(word_list).value_counts()\n",
    "        # removing disturbance words.\n",
    "    word_freq = word_freq.drop(STOP_WORDS, errors='ignore')\n",
    "\n",
    "    return word_freq\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativity(words):\n",
    "    for word in words:\n",
    "        # if any word contains the given value then 1 otherwise 0 will be written.\n",
    "        if word in ['n', 'not', 'non', 'no'] or re.search(r\"\\n't\", word):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rare_words(words, rare_100):\n",
    "    for word in words:\n",
    "        # for rare word encoding will be 1 otherwise 0.\n",
    "        if word in rare_100:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question(words):\n",
    "    for word in words:\n",
    "        # for question comment encoding will be 1 otherwise 0.\n",
    "        if word in ['what', 'when', 'how', 'why', 'who']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducing new columns using lambda as we did see before.\n",
    "word_freq = freq_creation(df['clean_text'].str)\n",
    "\n",
    "least_100 = word_freq[-100:]\n",
    "\n",
    "df['word_count'] = df['clean_text'].str.split().apply(lambda x: len(x))\n",
    "\n",
    "df['negatives'] = df['clean_text'].str.split().apply(lambda x: negativity(x))\n",
    "\n",
    "df['question'] = df['clean_text'].str.split().apply(lambda x: is_question(x))\n",
    "\n",
    "df['word_rare'] = df['clean_text'].str.split().apply(lambda x: rare_words(x, least_100))\n",
    "\n",
    "\n",
    "df['chr_count'] = df['clean_text'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "source": [
    "Explortion is required"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn for modelling \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['chr_count', 'word_rare', 'word_count', 'question', 'negatives']]\n",
    "\n",
    "y = df['label']\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(X, y, random_state= 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier modelling & fitting on train data. \n",
    "nb = GaussianNB()\n",
    "nbfit = nb.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4248665141113654"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# predicting for test dataset, using only \n",
    "pred = nb.predict(testx)\n",
    "accuracy_score(testy, pred)"
   ]
  },
  {
   "source": [
    "**Concluding remarks: We have attempted to create a model which can classify tweets either if it is a hate speech or not. Although the accuracy score for our model is not upto the mark. But for sure once the data size will increase the model performance will also increase.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}